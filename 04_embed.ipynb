{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749ef832",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import statistics\n",
    "import torch\n",
    "from sentence_transformers import SentenceTransformer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7acd2de",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELS = {\n",
    "    \"minilm\": \"sentence-transformers/all-MiniLM-L6-v2\",\n",
    "    \"e5_small\": \"intfloat/e5-small-v2\",\n",
    "    \"bge_small\": \"BAAI/bge-small-en-v1.5\",\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb6cbd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_texts(model_key, texts, as_query=False):\n",
    "    if model_key.startswith(\"e5\"):\n",
    "        prefix = \"query: \" if as_query else \"passage: \"\n",
    "        return [prefix + t for t in texts]\n",
    "    return texts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0dd0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bench(\n",
    "    model_name,\n",
    "    texts,\n",
    "    device=\"cpu\",\n",
    "    batch_size=64,\n",
    "    max_seq_length=256,\n",
    "    runs=10,\n",
    "    warmup=2,\n",
    "):\n",
    "    model = SentenceTransformer(model_name, device=device)\n",
    "    model.max_seq_length = max_seq_length\n",
    "\n",
    "    # Warmup\n",
    "    for _ in range(warmup):\n",
    "        _ = model.encode(\n",
    "            texts[:batch_size],\n",
    "            batch_size=batch_size,\n",
    "            normalize_embeddings=False,\n",
    "            show_progress_bar=False,\n",
    "        )\n",
    "\n",
    "    times = []\n",
    "    for _ in range(runs):\n",
    "        if device.startswith(\"cuda\"):\n",
    "            torch.cuda.synchronize()\n",
    "\n",
    "        t0 = time.perf_counter()\n",
    "\n",
    "        _ = model.encode(\n",
    "            texts,\n",
    "            batch_size=batch_size,\n",
    "            normalize_embeddings=False,\n",
    "            show_progress_bar=False,\n",
    "        )\n",
    "\n",
    "        if device.startswith(\"cuda\"):\n",
    "            torch.cuda.synchronize()\n",
    "\n",
    "        t1 = time.perf_counter()\n",
    "        times.append(t1 - t0)\n",
    "\n",
    "    total = len(texts)\n",
    "    median = statistics.median(times)\n",
    "    p90 = statistics.quantiles(times, n=10)[8]\n",
    "\n",
    "    return {\n",
    "        \"model\": model_name,\n",
    "        \"device\": device,\n",
    "        \"batch_size\": batch_size,\n",
    "        \"max_seq_length\": max_seq_length,\n",
    "        \"texts\": total,\n",
    "        \"median_s\": round(median, 4),\n",
    "        \"p90_s\": round(p90, 4),\n",
    "        \"throughput_texts_per_s\": round(total / median, 2),\n",
    "        \"latency_ms_per_text\": round((median / total) * 1000, 3),\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109120c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 3483)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_text = \"This is a sample paragraph used for embedding benchmarks. \" * 60\n",
    "texts = [f\"{i}. {base_text}\" for i in range(2000)]\n",
    "\n",
    "len(texts), len(texts[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6e6fb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffdc4f09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'model': 'sentence-transformers/all-MiniLM-L6-v2',\n",
       "  'device': 'cpu',\n",
       "  'batch_size': 64,\n",
       "  'max_seq_length': 256,\n",
       "  'texts': 2000,\n",
       "  'median_s': 23.9747,\n",
       "  'p90_s': 24.7109,\n",
       "  'throughput_texts_per_s': 83.42,\n",
       "  'latency_ms_per_text': 11.987},\n",
       " {'model': 'intfloat/e5-small-v2',\n",
       "  'device': 'cpu',\n",
       "  'batch_size': 64,\n",
       "  'max_seq_length': 256,\n",
       "  'texts': 2000,\n",
       "  'median_s': 46.1582,\n",
       "  'p90_s': 47.037,\n",
       "  'throughput_texts_per_s': 43.33,\n",
       "  'latency_ms_per_text': 23.079},\n",
       " {'model': 'BAAI/bge-small-en-v1.5',\n",
       "  'device': 'cpu',\n",
       "  'batch_size': 64,\n",
       "  'max_seq_length': 256,\n",
       "  'texts': 2000,\n",
       "  'median_s': 45.9232,\n",
       "  'p90_s': 46.3682,\n",
       "  'throughput_texts_per_s': 43.55,\n",
       "  'latency_ms_per_text': 22.962}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "for key, model_name in MODELS.items():\n",
    "    prepared_texts = prep_texts(key, texts, as_query=False)\n",
    "    res = bench(\n",
    "        model_name,\n",
    "        prepared_texts,\n",
    "        device=device,\n",
    "        batch_size=64,\n",
    "        max_seq_length=256,\n",
    "    )\n",
    "    results.append(res)\n",
    "\n",
    "results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a26952d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>device</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>max_seq_length</th>\n",
       "      <th>texts</th>\n",
       "      <th>median_s</th>\n",
       "      <th>p90_s</th>\n",
       "      <th>throughput_texts_per_s</th>\n",
       "      <th>latency_ms_per_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sentence-transformers/all-MiniLM-L6-v2</td>\n",
       "      <td>cpu</td>\n",
       "      <td>64</td>\n",
       "      <td>256</td>\n",
       "      <td>2000</td>\n",
       "      <td>23.9747</td>\n",
       "      <td>24.7109</td>\n",
       "      <td>83.42</td>\n",
       "      <td>11.987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>intfloat/e5-small-v2</td>\n",
       "      <td>cpu</td>\n",
       "      <td>64</td>\n",
       "      <td>256</td>\n",
       "      <td>2000</td>\n",
       "      <td>46.1582</td>\n",
       "      <td>47.0370</td>\n",
       "      <td>43.33</td>\n",
       "      <td>23.079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BAAI/bge-small-en-v1.5</td>\n",
       "      <td>cpu</td>\n",
       "      <td>64</td>\n",
       "      <td>256</td>\n",
       "      <td>2000</td>\n",
       "      <td>45.9232</td>\n",
       "      <td>46.3682</td>\n",
       "      <td>43.55</td>\n",
       "      <td>22.962</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    model device  batch_size  max_seq_length  \\\n",
       "0  sentence-transformers/all-MiniLM-L6-v2    cpu          64             256   \n",
       "1                    intfloat/e5-small-v2    cpu          64             256   \n",
       "2                  BAAI/bge-small-en-v1.5    cpu          64             256   \n",
       "\n",
       "   texts  median_s    p90_s  throughput_texts_per_s  latency_ms_per_text  \n",
       "0   2000   23.9747  24.7109                   83.42               11.987  \n",
       "1   2000   46.1582  47.0370                   43.33               23.079  \n",
       "2   2000   45.9232  46.3682                   43.55               22.962  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a136b5",
   "metadata": {
    "solveit_ai": true,
    "time_run": "2026-01-24T21:47:15.425517+00:00"
   },
   "source": [
    "i want to use the bge small en v1.5 on my 'text' column in 'chunks' table in my scrape.db. i am using fastlite\n",
    "\n",
    "##### ðŸ¤–ReplyðŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ \n",
    "\n",
    "```python\n",
    "from fastlite import database\n",
    "```\n",
    "\n",
    "```python\n",
    "db = database(\"scrape.db\")\n",
    "db.t.chunks\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42330a0c",
   "metadata": {
    "time_run": "2026-01-24T22:04:46.153879+00:00"
   },
   "outputs": [],
   "source": [
    "from fastlite import database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c148f8cd",
   "metadata": {
    "time_run": "2026-01-24T22:04:47.907480+00:00"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Table chunks (does not exist yet)>"
      ]
     },
     "execution_count": 0,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db = database(\"scrape.db\")\n",
    "db.t.chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5740414",
   "metadata": {
    "time_run": "2026-01-24T22:05:31.268734+00:00"
   },
   "outputs": [],
   "source": [
    "db.t.all()"
   ]
  }
 ],
 "metadata": {
  "solveit_dialog_mode": "concise",
  "solveit_ver": 2
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
